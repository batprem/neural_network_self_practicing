{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape to be [samples][width][height][channels]\n",
    "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert from int to float\n",
    "X_train = X_train/255.0\n",
    "X_test = X_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(y_train.reshape(-1,1))\n",
    "y_train_tran = enc.transform(y_train.reshape(-1,1))\n",
    "y_train_tran = y_train_tran.toarray()\n",
    "\n",
    "y_test_tran = enc.transform(y_test.reshape(-1,1))\n",
    "y_test_tran = y_test_tran.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genarate Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "                    # featurewise_center=True,\n",
    "                    # featurewise_std_normalization=True,\n",
    "                    horizontal_flip=False,\n",
    "                    vertical_flip=False,\n",
    "                    height_shift_range=1,\n",
    "                    #zoom_range=[2, 2]\n",
    "                    zoom_range=0.05,\n",
    "                    rotation_range=30\n",
    "                )\n",
    "datagen.fit(X_train)\n",
    "for X_batch, y_batch in datagen.flow(X_train, y_train_tran, batch_size=9):\n",
    "    # create a grid of 3x3 images\n",
    "    for i in range(0, 9):\n",
    "        print(y_batch)\n",
    "        pyplot.subplot(330 + 1 + i)\n",
    "        pyplot.imshow(X_batch[i].reshape(28, 28), cmap=pyplot.get_cmap('gray'))\n",
    "    # show the plot\n",
    "    pyplot.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from keras.layers import (Input, Concatenate, concatenate, Dropout,\n",
    "                          BatchNormalization, Conv2D, Flatten, Dense, MaxPooling2D)\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "\n",
    "def getCheckPoint(filepath, monitor, verbose=1, mode='min'):\n",
    "    return ModelCheckpoint(filepath,\n",
    "                           monitor=monitor,\n",
    "                           verbose=verbose,\n",
    "                           save_best_only=True,\n",
    "                           include_optimizer = False,\n",
    "                           mode=mode)\n",
    "\n",
    "def getEarlyStop(monitor, verbose=1, mode='min'):\n",
    "    return EarlyStopping(monitor=monitor, mode = 'min', patience=5)\n",
    "\n",
    "# Get get hyper param\n",
    "early_stop = getEarlyStop('val_loss')\n",
    "# checkpoint = getCheckPoint('Best_model_with_{val_loss:.5}.model', 'val_loss')\n",
    "\n",
    "checkpoint = getCheckPoint('Best_model.model', 'val_loss')\n",
    "\n",
    "InputLayer = Input(shape=X_train[0].shape)\n",
    "\n",
    "# Shape: (28, 28, 1)\n",
    "Filter_number = 32\n",
    "Conv2D_layer = Conv2D(Filter_number, (3, 3), input_shape=X_train[0].shape)(InputLayer)\n",
    "# Shape: (1, 28 -3 + 1, 28 -3 +1, Filter_number) = (1, 26, 26, 32)\n",
    "\n",
    "Pool_size = (2, 2)\n",
    "max_pooling_layer = MaxPooling2D((2, 2))(Conv2D_layer)\n",
    "# Shape: ((1, 26/pool size[0], 26/pool size[1], 32))\n",
    "# OutputLayer = Dense(1, activation='sigmoid')(Conv2D_layer)\n",
    "\n",
    "flatten_layer = Flatten()(max_pooling_layer)\n",
    "\n",
    "output_layer = Dense(100, activation='sigmoid')(flatten_layer)\n",
    "for dense_out in [10]:\n",
    "    output_layer = Dropout(0.4)(output_layer, training=True)\n",
    "    output_layer = Dense(dense_out, activation='sigmoid')(output_layer)\n",
    "\n",
    "\n",
    "model = Model(inputs=InputLayer, outputs=output_layer)\n",
    "\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise Cool things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "Conv_map = model.predict(np.array([X_batch[0]]))\n",
    "# pyplot.imshow(Conv_map.reshape(28, 28), cmap=pyplot.get_cmap('gray'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n",
      "(1, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_batch[0].shape)\n",
    "print(Conv_map.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Conv_map[0,...,1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid shape () for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-6865f8854252>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m330\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;31m# show the plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/buddy/lib/python3.8/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2669\u001b[0m         \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deprecated_parameter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2670\u001b[0m         resample=None, url=None, *, data=None, **kwargs):\n\u001b[0;32m-> 2671\u001b[0;31m     __ret = gca().imshow(\n\u001b[0m\u001b[1;32m   2672\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maspect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maspect\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2673\u001b[0m         \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/buddy/lib/python3.8/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1597\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/buddy/lib/python3.8/site-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    367\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/buddy/lib/python3.8/site-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    367\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/buddy/lib/python3.8/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5677\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5679\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5680\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5681\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/buddy/lib/python3.8/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    687\u001b[0m         if not (self._A.ndim == 2\n\u001b[1;32m    688\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[0;32m--> 689\u001b[0;31m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[0m\u001b[1;32m    690\u001b[0m                             .format(self._A.shape))\n\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid shape () for image data"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAG0AAABjCAYAAACR8o4mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAEjElEQVR4nO2dQWgcVRjHf39Tq5CDBZuDaKEWiyEHD+kiOZWCCG0PyUEP6aVGKqFo8Sx4EHqRnoSiWIIGrYda7CmCIoJCT63dgNZWUbaCGAk0rZKLUA18HmbSrJvd7HR9k9mPfD8YmJn33rwv+TGzb1/yvZGZEfjivqoDCO6dkOaQkOaQkOaQkOaQkOaQrtIkzUq6Kelah3JJOi2pIemqpNH0YQbNFLnTPgAOblB+CNibb9PAu/8/rGAjukozs4vAHxtUmQDOWsYlYIekR1IFGKwnxWfao8BvTccL+bmgJLZtZmeSpskeoQwODu4bHh7ezO77ivn5+VtmNtRL2xTSfgd2NR0/lp9bh5nNADMAtVrN6vV6gu59IunXXtumeDzOAUfzUeQYsGxmiwmuG3Sg650m6RxwANgpaQF4A7gfwMzOAJ8Bh4EG8BfwYlnBBhldpZnZkS7lBrySLKKgKzEj4pCQ5pCQ5pCQ5pCQ5pCQ5pCQ5pCQ5pCQ5pCQ5pCQ5pCQ5pCQ5pCQ5pCQ5pCQ5pCQ5pCQ5pCQ5pCQ5pCQ5pCQ5pCQ5pBC0iQdlPRTnoP2WpvyKUlLkr7Nt5fShxqsUuQ/jAeAd4BnyTJirkiaM7MfWqqeN7MTJcQYtFDkTnsaaJjZL2b2N/AxWU5aUBFFpBXNP3suT9+9IGlXm/IgEakGIp8Cu83sKeBL4MN2lSRNS6pLqi8tLSXqeutRRFrX/DMzu21md/LD94B97S5kZjNmVjOz2tBQT/l0AcWkXQH2Snpc0nZgkiwn7S4tOdbjwI/pQgxaKZLqtCLpBPAFMADMmtl1SSeBupnNAa9KGgdWyJLqp0qMecujqpYOjPRdzZtZrZe2MSPikJDmkJDmkJDmkJDmkJDmkJDmkJDmkJDmkJDmkJDmkJDmkJDmkJDmkJDmkJDmkJDmkJDmkJDmkJDmkJDmkJDmkJDmkFT5aQ9IOp+XX5a0O3WgwRpFXnq3mp92CBgBjkgaaal2DPjTzJ4A3gJOpQ40WCNVftoEa5kyF4BnJCldmEEzqfLT7tYxsxVgGXg4RYDBeip7fxpwp9N7RjeJncCtCvt/steGRaQVeT/aap0FSduAh4DbrRdqfn+apHqvCQgp6If+e22bJD8tP34h338e+MqqSsfZAqTKT3sf+EhSgyw/bbLMoLc8ZlbJBkxX1bf3/itLKgx6J6axHFK6tKqnwKpcIkrSrKSbnb7a5C+/PZ3HdlXSaKELl/zcHgBuAHuA7cB3wEhLnZeBM/n+JNlyTZvZ/xTwdkk//35gFLjWofww8DkgYAy4XOS6Zd9pVU+BVbpElJldJBtNd2ICOGsZl4AdLct7tKVsaVVPgfX7ElFF4/sPMRApuERUP1G2tHuZAmOjKbCy+reCS0SVRJHfzzrKllb1FFi/LxE1BxzNR5FjwLKZLXZtVebosWmE9DPZKO71/NxJYDzffxD4BGgA3wB7Nrn/N4HrZCPLr4HhhH2fAxaBf8g+r44Bx4HjebnI/sB8A/geqBW5bsyIOCQGIg4JaQ4JaQ4JaQ4JaQ4JaQ4JaQ4JaQ75F4dklSLKRbF9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for filter_index in range(Conv_map.shape[-1]):\n",
    "    # create a grid of 3x3 images\n",
    "    for i in range(0, 9):\n",
    "        pyplot.subplot(330 + 1 + i)\n",
    "        pyplot.imshow(Conv_map[0,...,i], cmap=pyplot.get_cmap('gray'))\n",
    "    # show the plot\n",
    "    pyplot.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=InputLayer, outputs=MaxPooling)\n",
    "Max_pooling = model.predict(np.array([X_batch[0]]))\n",
    "Max_pooling.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filter_index in range(Conv_map.shape[-1]):\n",
    "    # create a grid of 3x3 images\n",
    "    for i in range(0, 9):\n",
    "        pyplot.subplot(330 + 1 + i)\n",
    "        pyplot.imshow(Max_pooling[0,...,1], cmap=pyplot.get_cmap('gray'))\n",
    "    # show the plot\n",
    "    pyplot.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dense(10)(np.array([[2,2]]), training=True).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_10 = Dense(10, activation='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dense_10(np.array([[2,2]])).numpy())\n",
    "print(Dropout(0.5, input_shape=(1, 10))(dense_10(np.array([[2,2]])) ,training=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=InputLayer, outputs=output_layer)\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              optimizer='adam',\n",
    "              metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "for i, (X_batch, Y_batch) in enumerate(datagen.flow(X_train, y_train_tran, batch_size=32)):\n",
    "    # create a grid of 3x3 images\n",
    "    print(f\"Batch: {i}\")\n",
    "    model.fit(X_batch, Y_batch, validation_data=(X_test, y_test_tran), epochs=100)\n",
    "    if i == 1:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1870/1875 [============================>.] - ETA: 0s - loss: 0.0886 - categorical_accuracy: 0.8628\n",
      "Epoch 00001: val_loss improved from inf to 0.05469, saving model to Best_model.model\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/buddy/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/buddy/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: Best_model.model/assets\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0886 - categorical_accuracy: 0.8629 - val_loss: 0.0547 - val_categorical_accuracy: 0.9268\n",
      "Epoch 2/200\n",
      "1874/1875 [============================>.] - ETA: 0s - loss: 0.0535 - categorical_accuracy: 0.9226\n",
      "Epoch 00002: val_loss improved from 0.05469 to 0.03524, saving model to Best_model.model\n",
      "INFO:tensorflow:Assets written to: Best_model.model/assets\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0535 - categorical_accuracy: 0.9226 - val_loss: 0.0352 - val_categorical_accuracy: 0.9527\n",
      "Epoch 3/200\n",
      "1875/1875 [==============================] - ETA: 0s - loss: 0.0408 - categorical_accuracy: 0.9426\n",
      "Epoch 00003: val_loss improved from 0.03524 to 0.02942, saving model to Best_model.model\n",
      "INFO:tensorflow:Assets written to: Best_model.model/assets\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0408 - categorical_accuracy: 0.9426 - val_loss: 0.0294 - val_categorical_accuracy: 0.9604\n",
      "Epoch 4/200\n",
      "1871/1875 [============================>.] - ETA: 0s - loss: 0.0359 - categorical_accuracy: 0.9502\n",
      "Epoch 00004: val_loss improved from 0.02942 to 0.02713, saving model to Best_model.model\n",
      "INFO:tensorflow:Assets written to: Best_model.model/assets\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0359 - categorical_accuracy: 0.9502 - val_loss: 0.0271 - val_categorical_accuracy: 0.9639\n",
      "Epoch 5/200\n",
      "1873/1875 [============================>.] - ETA: 0s - loss: 0.0329 - categorical_accuracy: 0.9542\n",
      "Epoch 00005: val_loss improved from 0.02713 to 0.02494, saving model to Best_model.model\n",
      "INFO:tensorflow:Assets written to: Best_model.model/assets\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.0329 - categorical_accuracy: 0.9542 - val_loss: 0.0249 - val_categorical_accuracy: 0.9656\n",
      "Epoch 6/200\n",
      "1870/1875 [============================>.] - ETA: 0s - loss: 0.0308 - categorical_accuracy: 0.9574\n",
      "Epoch 00006: val_loss improved from 0.02494 to 0.02424, saving model to Best_model.model\n",
      "INFO:tensorflow:Assets written to: Best_model.model/assets\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0308 - categorical_accuracy: 0.9574 - val_loss: 0.0242 - val_categorical_accuracy: 0.9670\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa03f265460>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getCheckPoint(filepath, monitor, verbose=1, mode='min'):\n",
    "    return ModelCheckpoint(filepath,\n",
    "                           monitor=monitor,\n",
    "                           verbose=verbose,\n",
    "                           save_best_only=True,\n",
    "                           include_optimizer = False,\n",
    "                           mode=mode)\n",
    "\n",
    "def getEarlyStop(monitor, verbose=1, mode='min'):\n",
    "    return EarlyStopping(monitor=monitor, mode = 'min', patience=5)\n",
    "\n",
    "\n",
    "# Get get hyper param\n",
    "early_stop = getEarlyStop('val_categorical_accuracy')\n",
    "# checkpoint = getCheckPoint('Best_model_with_{val_loss:.5}.model', 'val_loss')\n",
    "checkpoint = getCheckPoint('Best_model.model', 'val_loss')\n",
    "\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              optimizer='adam',\n",
    "              metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "model.fit(datagen.flow(X_train, y_train_tran, batch_size=32),\n",
    "          steps_per_epoch=len(X_train) / 32, epochs=200,\n",
    "          validation_data=(X_test, y_test_tran), batch_size=32,\n",
    "         callbacks = [checkpoint, early_stop],)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling = -8\n",
    "print(enc.inverse_transform(model.predict(X_test[sampling:sampling + 1])))\n",
    "print(y_test[sampling])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc.inverse_transform(model.predict(X_test[0:1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=InputLayer, outputs=output_layer)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "batch_size = int(500)\n",
    "\n",
    "# # Set tensor dataset\n",
    "# train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train_precessed))\n",
    "# # Set batch training\n",
    "# train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test_tran))\n",
    "val_dataset = val_dataset.batch(len(X_test))\n",
    "\n",
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(x, training=True)\n",
    "        loss_value = loss_fn(y, logits)\n",
    "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    train_acc_metric.update_state(y, logits)\n",
    "    return loss_value\n",
    "\n",
    "@tf.function\n",
    "def test_step(x, y):\n",
    "    val_logits = model(x, training=False)\n",
    "    val_acc_metric.update_state(y, val_logits)\n",
    "    \n",
    "# Looping\n",
    "\n",
    "epochs =  200\n",
    "# Prepare the metrics.\n",
    "train_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "val_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(datagen.flow(\n",
    "                    X_train,\n",
    "                    y_train_tran,\n",
    "                    batch_size=200)):\n",
    "        \n",
    "        loss_value = train_step(x_batch_train, y_batch_train)\n",
    "        break\n",
    "        if step % 200 == 0:\n",
    "            print(\n",
    "                \"Training loss (for one batch) at step %d: %.4f\"\n",
    "                % (step, float(loss_value))\n",
    "            )\n",
    "            print(\"Seen so far: %d samples\" % ((step + 1) * 64))\n",
    "    print(f\"Loss: {float(loss_value)}\")\n",
    "    # Display metrics at the end of each epoch.\n",
    "    train_acc = train_acc_metric.result()\n",
    "    print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
    "    \n",
    "    for x_batch_val, y_batch_val in val_dataset:\n",
    "        test_step(x_batch_val, y_batch_val)\n",
    "        \n",
    "    val_acc = val_acc_metric.result()\n",
    "    val_acc_metric.reset_states()\n",
    "    print(\"Validation acc: %.4f\" % (float(val_acc),))\n",
    "    print(\"=\"*36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
